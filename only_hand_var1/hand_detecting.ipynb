{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a78a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbe4f33b-de6a-4059-bc41-cdeefd1f29f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 모델 아키텍처 정의\n",
    "class HandStateNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(HandStateNN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(63, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, n_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "      return self.fc(x)\n",
    "\n",
    "# 학습된 모델 로드\n",
    "model = HandStateNN(n_classes=1)\n",
    "model.load_state_dict(torch.load('hand_model.pth', map_location=device)) # 모델 파일 경로 지정\n",
    "model.eval()\n",
    "\n",
    "# 한글 폰트 사용 시\n",
    "# 한글 폰트 경로 설정 \n",
    "# font_path = 'AppleGothic.ttf'\n",
    "# font = ImageFont.truetype(font_path, 20)\n",
    "\n",
    "# MediaPipe 손 모델 초기화\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# # 라렝링을 위한 레이블 이름 설정\n",
    "# labels_map = {\n",
    "#     0: 'Release',\n",
    "#     1: 'Folding hand',\n",
    "#     2: 'Grab'\n",
    "# }\n",
    "\n",
    "# 카메라 초기화\n",
    "cap = cv2.VideoCapture(1) # for Mac\n",
    "# cap = cv2.VideoCapture(0) # for Windows\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    # 이미지 전처리\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.flip(frame, 1)\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # 랜드마크 추출\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            landmarks = [(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark]\n",
    "            landmarks = torch.tensor([landmarks]).flatten().unsqueeze(0)\n",
    "    \n",
    "            # 모델을 사용하여 라벨 예측\n",
    "            with torch.no_grad():\n",
    "                predictions = model(landmarks)\n",
    "                predicted_label = torch.argmax(predictions, axis=1)\n",
    "                label_text = str(round(float(predictions.item()), 3))\n",
    "                # label_text = labels_map[int(predicted_label.item())]\n",
    "    \n",
    "                # # 한글 폰트 사용 시\n",
    "                # # PIL을 사용하여 한글 라벨링\n",
    "                # img_pil = Image.fromarray(frame)\n",
    "                # draw = ImageDraw.Draw(img_pil)ㅂ\n",
    "                # draw.text((10, 30), label_text, font=font, fill=(0, 255, 0))\n",
    "                # frame = np.array(img_pil)\n",
    "                \n",
    "                # 화면에 랜드마크 그리기 및 라벨링 표시\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                cv2.putText(image, label_text, (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "    # 화면에 결과 보여주기\n",
    "    cv2.imshow('Hand State Recognition', image)\n",
    "\n",
    "    # 'q'를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1) # for Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c8f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d92972-6454-4218-ac72-7b90baaa4743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
