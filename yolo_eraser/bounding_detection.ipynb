{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHEvnQet5SjV+wRliqAyot"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2t4pv2pWmUV",
        "outputId": "6fb5ea1d-611f-4731-9e8d-773298278778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics\n",
        "%pip install mediapipe\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "5230_lH_X58l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f22b439-5553-4211-843e-5165160593f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.227 🚀 Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 27.1/225.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "from ultralytics import YOLO\n",
        "import torch"
      ],
      "metadata": {
        "id": "7W_0eHXVX6jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# mediapipe 손 감지 모듈 초기화\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "best_model = '/content/drive/MyDrive/Deep_learning_Team_PJ/hand_tracing/yolo_eraser/best.pt'\n",
        "# best_model = 'best.pt'\n",
        "\n",
        "\n",
        "# YOLO 객체 감지 모델 초기화\n",
        "yolo_model = YOLO(best_model)\n",
        "\n",
        "prev_boxes = []\n",
        "\n",
        "cap = cv2.VideoCapture(1) # for Mac\n",
        "# cap = cv2.VideoCapture(0) # for Windows\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # BGR 이미지를 RGB로 변환\n",
        "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.flip(frame, 1)\n",
        "    results = hands.process(image)\n",
        "\n",
        "    # YOLO 객체 감지\n",
        "    bboxes = yolo_model.detect_objects(image)\n",
        "\n",
        "\n",
        "    # 객체 감지 결과를 이미지에 표시\n",
        "    if bboxes.shape[0] > 0:\n",
        "      prev_boxes = bboxes\n",
        "      for bbox in bboxes:\n",
        "          x1, y1, x2, y2 = bbox\n",
        "          cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "    else:\n",
        "      if prev_boxes:\n",
        "        for prev_box in prev_boxes:\n",
        "            for box in bboxes:\n",
        "                iou = (min(prev_box[2], box[2]) - max(prev_box[0], box[0])) * \\\n",
        "                      (min(prev_box[3], box[3]) - max(prev_box[1], box[1])) / \\\n",
        "                      float((prev_box[2] - prev_box[0]) * (prev_box[3] - prev_box[1]) +\n",
        "                            (box[2] - box[0]) * (box[3] - box[1]))\n",
        "\n",
        "                if iou > 0.5:\n",
        "                    cv2.rectangle(frame, (int(prev_box[0]), int(prev_box[1])),\n",
        "                                  (int(prev_box[2]), int(prev_box[3])), (0, 255, 0), 2)\n",
        "                    break\n",
        "\n",
        "    if results.multi_hand_landmarks:\n",
        "        for hand_landmarks in results.multi_hand_landmarks:\n",
        "              with torch.no_grad():\n",
        "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
        "\n",
        "\n",
        "    cv2.imshow('Frame', image)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "It8hXZVKXWdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-y0oMpbbWllB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}